{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "title: Predicting NES game prices on eBay - part 1: data preparation    \n",
    "date: 2016-04-10  \n",
    "comments: false  \n",
    "tags: Python, Programming tips, Public Data   \n",
    "keywords: python, programming, virtualenv, virtualfish, reproducible research  \n",
    "\n",
    "---\n",
    "\n",
    "As a kid I was addicted to my NES, and have many fond memories of hours spent on the Super Mario Bros. and Zelda games. In fact, I attribute those early NES games to my current love of RPGs (and conversely, my hatred of really difficult games).\n",
    "\n",
    "<img src=\"/figure/Zelda_error.png\" title=\"I am Error\" alt=\"Another word lost in translation\" style=\"display: block; margin: auto;\" />\n",
    "\n",
    "My boyfriend has recently started collecting original NES cartridges, and has been scouring eBay to build his collection. Given that some of the rare cartridges can go for upward of $500, working out how to get the best price can lead to significant savings on some games. I decided to apply a scientific approach to this problem and have taken advantage of the eBay API to extract data on recent sales of a number of NES games.\n",
    "\n",
    "# Setting up your environment\n",
    "As always when I am using Python, I started by setting up a virtualenv with all of the necessary packages (see my [previous blog post]() for how - and why! - to do this). For this exercise, I set up a virtualenv with the following packages: `numpy`, `pandas`, `scipy` and `matplotlib`. Following this, I imported `urllib2`, `json`, `math`, `numpy`, `pandas` and `pandas` Series and DataFrames separately.\n",
    "\n",
    "[Top NES music](https://www.youtube.com/watch?v=UNA3Laa3-_Q)\n",
    "[100 NES games]()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jburchell/.virtualenvs/ebay_api/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    }
   ],
   "source": [
    "import urllib2\n",
    "import json\n",
    "import math\n",
    "\n",
    "import numpy as np\n",
    "from pandas import Series, DataFrame\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "I then created a function that pulls expired listings for keywords of choice using the eBay API and then pops all of the data I want in a `pandas DataFrame`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expired_listings(site, searchterm):\n",
    "    '''Extracts the total historical listings from eBay for specific keywords and a specific global ID (eBay site), and then passes the results into a pandas DataFrame.'''\n",
    "    # Find out the number of pages of listings with the default number of listings per page.\n",
    "    url = 'http://svcs.ebay.com/services/search/FindingService/v1?OPERATION-NAME=findCompletedItems&SERVICE-VERSION=1.12.0&SECURITY-APPNAME=<insert appname here>&GLOBAL-ID=%s&RESPONSE-DATA-FORMAT=JSON&REST-PAYLOAD&keywords=%s&paginationInput.entriesPerPage=1' % (site, searchterm)\n",
    "    req = urllib2.Request(url)\n",
    "    text_data = urllib2.urlopen(req).read()\n",
    "    test = json.loads(text_data)\n",
    "    max = 1 + int(math.ceil(float(test.values()[0][0]['paginationOutput'][0]['totalEntries'][0]) / 100))\n",
    "\n",
    "    # Extract all listings and add the JSON to a single list.\n",
    "    data_all = []\n",
    "    for i in range(1, max):\n",
    "        url = 'http://svcs.ebay.com/services/search/FindingService/v1?OPERATION-NAME=findCompletedItems&SERVICE-VERSION=1.12.0&SECURITY-APPNAME=<insert appname here>&GLOBAL-ID=%s&RESPONSE-DATA-FORMAT=JSON&REST-PAYLOAD&keywords=%s&paginationInput.pageNumber=%d' % (site, searchterm, i)\n",
    "        req = urllib2.Request(url)\n",
    "        text_data = urllib2.urlopen(req).read()\n",
    "        data = json.loads(text_data)\n",
    "        data_all += data.values()[0][0]['searchResult'][0]['item']\n",
    "    \n",
    "    # Prepare the columns in the dataframe.\n",
    "    title = []\n",
    "    location = []\n",
    "    eBay_site = []\n",
    "    start_time = []\n",
    "    end_time = []\n",
    "    category = []\n",
    "    listing_type = []\n",
    "    item_condition = []\n",
    "    listing_sold = []\n",
    "    shipping_locations = []\n",
    "    shipping_cost = []\n",
    "    ending_price = []\n",
    "    currency = []\n",
    "    \n",
    "    # Pass the information from each listing into the column lists.\n",
    "    for i in range(0, len(data_all)):\n",
    "        title.append(data_all[i]['title'][0])\n",
    "        location.append(data_all[i]['location'][0])\n",
    "        eBay_site.append(data_all[i]['globalId'][0])\n",
    "        start_time.append(data_all[i]['listingInfo'][0]['startTime'][0])\n",
    "        end_time.append(data_all[i]['listingInfo'][0]['endTime'][0])\n",
    "        category.append(data_all[i]['primaryCategory'][0]['categoryName'][0])\n",
    "        listing_type.append(data_all[i]['listingInfo'][0]['listingType'][0])\n",
    "        if 'condition' in data_all[i]:\n",
    "            item_condition.append(data_all[i]['condition'][0]['conditionId'][0])\n",
    "        else:\n",
    "            item_condition.append(0)\n",
    "        listing_sold.append(data_all[i]['sellingStatus'][0]['sellingState'][0])\n",
    "        shipping_locations.append(data_all[i]['shippingInfo'][0]['shipToLocations'][0])\n",
    "        if 'shippingServiceCost' in data_all[i]['shippingInfo'][0]:\n",
    "            shipping_cost.append(data_all[i]['shippingInfo'][0]['shippingServiceCost'][0]['__value__'])\n",
    "        else:\n",
    "            shipping_cost.append(0)\n",
    "        ending_price.append(data_all[i]['sellingStatus'][0]['convertedCurrentPrice'][0]['__value__'])\n",
    "        currency.append(data_all[i]['sellingStatus'][0]['convertedCurrentPrice'][0]['@currencyId'])\n",
    "    \n",
    "    title = [t.encode('utf8') for t in title]\n",
    "    \n",
    "    # Pass all of the column lists into a DataFrame.\n",
    "    nes_df = DataFrame({'Title': title,\n",
    "                        'Location': location,\n",
    "                        'eBaySite': eBay_site,\n",
    "                        'StartDateTime': start_time,\n",
    "                        'EndDateTime': end_time,\n",
    "                        'Category': category,\n",
    "                        'ListingType': listing_type,\n",
    "                        'ItemCondition': item_condition,\n",
    "                        'ListingSold': listing_sold,\n",
    "                        'ShippingLocations': shipping_locations,\n",
    "                        'ShippingCost': shipping_cost,\n",
    "                        'EndingPrice': ending_price,\n",
    "                        'Currency': currency})\n",
    "    nes_df = nes_df[['Title', 'Location', 'eBaySite', 'StartDateTime', 'EndDateTime', 'Category',\n",
    "                     'ListingType', 'ItemCondition', 'ListingSold', 'ShippingLocations',\n",
    "                     'ShippingCost', 'EndingPrice', 'Currency']]\n",
    "    return nes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function is a bit complicated, so let's break it down a little. \n",
    "\n",
    "# Step 1: Working with the eBay API\n",
    "The eBay API is very well documented, and surprisingly easy to work with. The first step to working with the API is work out which API you want. We will be looking up items, so we want to using the [Finding API](http://developer.ebay.com/devzone/finding/concepts/findingapiguide.html#work). You can see in the previous link that to work with the Finding API, you need an App-ID to authenticate your specific calls. \n",
    "\n",
    "This leads to the next step, which is to create a developer's account [here](https://go.developer.ebay.com/). Once you have your account, you can create your App-ID. Do this by going to the first dropdown menu at the top of the screen and selecting 'Application Access Keys':\n",
    "\n",
    "<img src=\"/figure/ebay_App_ID_1.png\" title=\"Getting an application ID\" alt=\"\" style=\"display: block; margin: auto;\" />\n",
    "\n",
    "Note that as we will be extracting data from the eBay website, you need to generate a _production_ key, not a sandbox key. Also, these are the keys you'll be stuck with for most of your dealings with the eBay API, so make sure to choose a name that will generalise across projects. Once you've generated your keys, you'll be presented with your 'App ID', 'Dev ID' and your 'Cert ID'. As shown below, the one you're interested in is your 'App ID'.\n",
    "\n",
    "<img src=\"/figure/ebay_App_ID_2.png\" title=\"Showing your App ID\" alt=\"\" style=\"display: block; margin: auto;\" />\n",
    "\n",
    "Now that we have our App ID, we can start working out how to get the information we want out of the Finding API. To get started, we write in the first part of the call:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'http://svcs.ebay.com/services/search/FindingService/v1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are getting historical data, we need to use the 'findCompletedItems' call. We'll add this to the base call above:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'http://svcs.ebay.com/services/search/FindingService/v1?OPERATION-NAME=findCompletedItems&SERVICE-VERSION=1.12.0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we add in our App ID using the 'SECURITY-APPNAME' option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'http://svcs.ebay.com/services/search/FindingService/v1?OPERATION-NAME=findCompletedItems&SERVICE-VERSION=1.12.0'\n",
    "    '&SECURITY-APPNAME=<insert appname here>'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can start customising our call to get the relevant information. [This guide](http://developer.ebay.com/devzone/finding/callref/findCompletedItems.html) lists all of the options you can add to your API call. I've chosen to use:\n",
    "- 'GLOBAL-ID=EBAY-AU': this option allows you to specify which eBay site you want to pull information from. In this example, I've used ebay.com.au. The full list of values is [here](http://developer.ebay.com/devzone/finding/callref/Enums/GlobalIdList.html).\n",
    "- 'RESPONSE-DATA-FORMAT=JSON&REST-PAYLOAD': this indicates that I want the call to return my data in JSON format.\n",
    "- 'keywords=super%20mario%20bros%20nes': these are the keywords that you want to search for. In this example, I've searched for 'Super Mario Bros NES'. Note that you need to separate each word using %20.\n",
    "- 'paginationInput.entriesPerPage=1': this indicates the number of results per page. In this example, I've chosen 1 result per page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'http://svcs.ebay.com/services/search/FindingService/v1?OPERATION-NAME=findCompletedItems&SERVICE-VERSION=1.12.0'\n",
    "    '&SECURITY-APPNAME=<insert appname here>'\n",
    "    '&GLOBAL-ID=EBAY-AU'\n",
    "    '&RESPONSE-DATA-FORMAT=JSON&REST-PAYLOAD'\n",
    "    '&keywords=super%20mario%20bros%20nes'\n",
    "    '&paginationInput.entriesPerPage=1'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this function, we can get a dataframe containing the eBay information on all of the games we want. I'll extract information on the following games:\n",
    "- Super Mario Bros.\n",
    "- Super Mario Bros. 2\n",
    "- Super Mario Bros. 3\n",
    "- Excitebike\n",
    "- Duck Hunt\n",
    "- Ice Climber\n",
    "- Mach Rider\n",
    "- Hogan's Alley\n",
    "- The Legend of Zelda\n",
    "- Zelda II: The Adventures of Link\n",
    "- Probotector \n",
    "- Probotector II: Return of the Evil Forces\n",
    "- Castlevania\n",
    "- Castlevania II: Simon's Quest\n",
    "- Castlevania III: Dracula's Curse\n",
    "- Kirby's Adventure\n",
    "- Teenage Mutant Ninja Turtles\n",
    "- Teenage Mutant Ninja Turtles II: The Arcade Game\n",
    "- Top Gun\n",
    "- Faxanadu\n",
    "- Battletoads\n",
    "- Solstice\n",
    "- California Games\n",
    "- Batman\n",
    "- Double Dragon\n",
    "- Double Dragon II: The Revenge\n",
    "- The Simpsons: Bart vs the World\n",
    "- The Simpsons: Bartman Meets Radioactive Man\n",
    "- The Simpsons: Krusty's Fun House\n",
    "- The Simpsons: Bart vs The Space Mutants\n",
    "- Mega Man\n",
    "- Mega Man 2\n",
    "- Mega Man 3\n",
    "- Mega Man 4\n",
    "- Donkey Kong\n",
    "- Donkey Kong Jr.\n",
    "- Donkey Kong 3\n",
    "- Donkey Kong Jr. Math\n",
    "- Mike Tyson's Punch-Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"teenage%20mutant%20ninja%20turtles%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"teenage%20mutant%20ninja%20turtles%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"teenage%20mutant%20ninja%20turtles%20nes\")\n",
    "\n",
    "nes_df = pd.concat([t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"probotector%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"probotector%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"probotector%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"kirby%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"kirby%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"kirby%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"super%20mario%20bros%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"super%20mario%20bros%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"super%20mario%20bros%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"zelda%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"zelda%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"zelda%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"castlevania%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"castlevania%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"castlevania%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"top%20gun%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"top%20gun%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"top%20gun%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"mega%20man%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"mega%20man%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"mega%20man%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"excitebike%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"excitebike%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"excitebike%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"duck%20hunt%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"duck%20hunt%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"duck%20hunt%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"kung%20fu%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"kung%20fu%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"kung%20fu%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"ice%20climber%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"ice%20climber%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"ice%20climber%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"faxanadu%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"faxanadu%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"faxanadu%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"mach%20rider%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"mach%20rider%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"mach%20rider%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"hogans%20alley%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"hogans%20alley%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"hogans%20alley%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"battletoads%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"battletoads%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"battletoads%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"simpsons%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"simpsons%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"simpsons%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"double%20dragon%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"double%20dragon%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"double%20dragon%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"solstice%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"solstice%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"solstice%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"batman%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"batman%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"batman%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"california%20games%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"california%20games%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"california%20games%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"donkey%20kong%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"donkey%20kong%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"donkey%20kong%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t1 = expired_listings(\"EBAY-AU\", \"tyson%20punch%20out%20nes\")\n",
    "t2 = expired_listings(\"EBAY-GB\", \"tyson%20punch%20out%20nes\")\n",
    "t3 = expired_listings(\"EBAY-IT\", \"tyson%20punch%20out%20nes\")\n",
    "\n",
    "nes_df = pd.concat([nes_df, t1, t2, t3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nes_df.to_csv('NesData.csv', encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Include only results from ebay.com.au, ebay.co.uk and ebay.it\n",
    "site = nes_df['eBaySite'].str.contains('AU|GB|IT')\n",
    "nes_df = nes_df.loc[(site),]\n",
    "\n",
    "# Include only results in a category that contains \"Games\" (or the Italian equivalent \"Giochi\")\n",
    "category = nes_df['Category'].str.contains('Games|Giochi')\n",
    "nes_df = nes_df.loc[(category),]\n",
    "\n",
    "# Exclude NTSC games, SNES games, Famicom games, and games that are in bundles/lots\n",
    "ex1 = nes_df['Title'].str.contains('^(?:(?!NTSC).)+$', flags = re.IGNORECASE)\n",
    "ex2 = nes_df['Title'].str.contains('^(?:(?!SNES).)+$', flags = re.IGNORECASE)\n",
    "ex3 = nes_df['Title'].str.contains('^(?:(?!Famicom).)+$', flags = re.IGNORECASE)\n",
    "ex4 = nes_df['Title'].str.contains('^(?:(?!N64).)+$', flags = re.IGNORECASE)\n",
    "ex5 = nes_df['Title'].str.contains('^(?:(?!Nintendo 64).)+$', flags = re.IGNORECASE)\n",
    "ex6 = nes_df['Title'].str.contains('^(?:(?!Wii).)+$', flags = re.IGNORECASE)\n",
    "ex7 = nes_df['Title'].str.contains('^(?:(?!Gameboy).)+$', flags = re.IGNORECASE)\n",
    "ex8 = nes_df['Title'].str.contains('^(?:(?!Game boy).)+$', flags = re.IGNORECASE)\n",
    "ex9 = nes_df['Title'].str.contains('^(?:(?!bundle).)+$', flags = re.IGNORECASE)\n",
    "ex10 = nes_df['Title'].str.contains('^(?:(?!lot).)+$', flags = re.IGNORECASE)\n",
    "ex11 = nes_df['Title'].str.contains('^(?:(?!sticker).)+$', flags = re.IGNORECASE)\n",
    "nes_df = nes_df.loc[(ex1 & ex2 & ex3 & ex4 & ex5 & ex6 & ex7 & ex8 & ex9 & ex10 & ex11),]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create variables to indicate if variable is complete in box, or has box or manual\n",
    "cond1 = nes_df['Title'].str.contains(\"CIB|completo\", flags = re.IGNORECASE)\n",
    "cond2 = nes_df['Title'].str.contains(\"box\", flags = re.IGNORECASE)\n",
    "cond3 = nes_df['Title'].str.contains(\"instruction|manual\", flags = re.IGNORECASE)\n",
    "cond4 = nes_df['Title'].str.contains(\"^(?:(?!CIB).)+$|^(?:(?!completo).)+$\", flags = re.IGNORECASE)\n",
    "cond5 = nes_df['Title'].str.contains(\"^(?:(?!box).)+$\", flags = re.IGNORECASE)\n",
    "cond6 = nes_df['Title'].str.contains(\"^(?:(?!instruction).)+$|^(?:(?!manual).)+$\", flags = re.IGNORECASE)\n",
    "\n",
    "nes_df['CIB'] = 0\n",
    "nes_df.loc[(cond1 | (cond2 & cond3)), 'CIB'] = 1\n",
    "\n",
    "nes_df['BoxOnly'] = 0\n",
    "nes_df.loc[((cond4 & cond6) & cond2), 'BoxOnly'] = 1\n",
    "\n",
    "nes_df['ManualOnly'] = 0\n",
    "nes_df.loc[((cond5 & cond6) & cond3), 'ManualOnly'] = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create variable with clean game titles\n",
    "nes_df['GameTitle'] = \"\"\n",
    "\n",
    "# Super Mario Bros.\n",
    "cond1 = nes_df['Title'].str.contains(\"Super Mario\", flags = re.IGNORECASE)\n",
    "cond2 = nes_df['Title'].str.contains(\"^(?:(?!2).)+$|^(?:(?!3).)+$\", flags = re.IGNORECASE)\n",
    "nes_df.loc[(cond1 & cond2), 'GameTitle'] = \"Super Mario Bros.\"\n",
    "\n",
    "# Super Mario Bros. 2\n",
    "cond1 = nes_df['Title'].str.contains(\"Super Mario\", flags = re.IGNORECASE)\n",
    "cond2 = nes_df['Title'].str.contains(\"2\", flags = re.IGNORECASE)\n",
    "nes_df.loc[(cond1 & cond2), 'GameTitle'] = \"Super Mario Bros. 2\"\n",
    "\n",
    "# Super Mario Bros. 3\n",
    "cond1 = nes_df['Title'].str.contains(\"Super Mario\", flags = re.IGNORECASE)\n",
    "cond2 = nes_df['Title'].str.contains(\"3\", flags = re.IGNORECASE)\n",
    "nes_df.loc[(cond1 & cond2), 'GameTitle'] = \"Super Mario Bros. 3\"\n",
    "\n",
    "# Excitebike\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"Excitebike|Excite bike\", flags = re.IGNORECASE), 'GameTitle'] = \"Excitebike\"\n",
    "\n",
    "# Duck Hunt\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"Duck Hunt|Duckhunt\", flags = re.IGNORECASE), 'GameTitle'] = \"Duck Hunt\"\n",
    "\n",
    "# Kung Fu\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"Kung Fu|KungFu\", flags = re.IGNORECASE), 'GameTitle'] = \"Kung Fu\"\n",
    "\n",
    "# Ice Climber\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"Ice Climber\", flags = re.IGNORECASE), 'GameTitle'] = \"Ice Climber\"\n",
    "\n",
    "# Mach Rider\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"Mach Rider\", flags = re.IGNORECASE), 'GameTitle'] = \"Mach Rider\"\n",
    "\n",
    "# Hogan's Alley\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"Hogan\", flags = re.IGNORECASE), 'GameTitle'] = \"Hogans Alley\"\n",
    "\n",
    "# The Legend of Zelda\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"Legend of Zelda\", flags = re.IGNORECASE), \n",
    "            'GameTitle'] = \"The Legend of Zelda\"\n",
    "\n",
    "# Zelda II: The Adventure of Link\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"Zelda II|Zelda 2|Adventures of Link|Adventure of Link\", flags = re.IGNORECASE), \n",
    "            'GameTitle'] = \"Zelda II The Adventure of Link\"\n",
    "\n",
    "# Probotector\n",
    "cond1 = nes_df['Title'].str.contains(\"Probotector\", flags = re.IGNORECASE)\n",
    "cond2 = nes_df['Title'].str.contains(\"^(?:(?!2).)+$|^(?:(?!Return of the Evil Forces).)+$\", flags = re.IGNORECASE)\n",
    "nes_df.loc[(cond1 & cond2), 'GameTitle'] = \"Probotector\"\n",
    "\n",
    "# Zelda II: The Adventures of Link\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"Probotector II|Probotector 2\", flags = re.IGNORECASE), \n",
    "            'GameTitle'] = \"Probotector II\"\n",
    "\n",
    "# Castlevania\n",
    "cond1 = nes_df['Title'].str.contains(\"Castlevania\", flags = re.IGNORECASE)\n",
    "cond2 = nes_df['Title'].str.contains(\"^(?:(?!Simon).)+$|^(?:(?!Dracula).)+$\", flags = re.IGNORECASE)\n",
    "nes_df.loc[(cond1 & cond2), 'GameTitle'] = \"Castlevania\"\n",
    "\n",
    "# Castlevania II: Simon's Quest\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"Castlevania II|Castlevania 2\", flags = re.IGNORECASE), \n",
    "            'GameTitle'] = \"Castlevania II\"\n",
    "\n",
    "# Castlevania III: Dracula's Curse\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"Castlevania III|Castlevania 3\", flags = re.IGNORECASE), \n",
    "            'GameTitle'] = \"Castlevania III\"\n",
    "\n",
    "# Kirby's Adventure\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"Kirby\", flags = re.IGNORECASE), \n",
    "            'GameTitle'] = \"Kirbys Adventure\"\n",
    "\n",
    "# Teenage Mutant Ninja Turtles\n",
    "cond1 = nes_df['Title'].str.contains(\"Teenage Mutant Ninja Turtles|TMNT|Teenage Mutant Hero Turtles\", \n",
    "                                      flags = re.IGNORECASE)\n",
    "cond2 = nes_df['Title'].str.contains(\"^(?:(?!2).)+$|^(?:(?!Arcade).)+$\", flags = re.IGNORECASE)\n",
    "nes_df.loc[(cond1 & cond2), 'GameTitle'] = \"Teenage Mutant Ninja Turtles\"\n",
    "\n",
    "# Teenage Mutant Ninja Turtles II\n",
    "cond1 = nes_df['Title'].str.contains(\"Teenage Mutant Ninja Turtles|TMNT|Teenage Mutant Hero Turtles\", \n",
    "                                      flags = re.IGNORECASE)\n",
    "cond2 = nes_df['Title'].str.contains(\"2|II|Arcade\", flags = re.IGNORECASE)\n",
    "nes_df.loc[(cond1 & cond2), 'GameTitle'] = \"Teenage Mutant Ninja Turtles II\"\n",
    "\n",
    "# Top Gun\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"Top Gun\", flags = re.IGNORECASE), \n",
    "            'GameTitle'] = \"Top Gun\"\n",
    "\n",
    "# Faxanadu\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"Faxanadu\", flags = re.IGNORECASE), \n",
    "            'GameTitle'] = \"Faxanadu\"\n",
    "\n",
    "# Battletoads\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"Battletoads|Battle toads\", flags = re.IGNORECASE), \n",
    "            'GameTitle'] = \"Battletoads\"\n",
    "\n",
    "# Solstice\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"Solstice\", flags = re.IGNORECASE), \n",
    "            'GameTitle'] = \"Solstice\"\n",
    "\n",
    "# California Games\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"California Games\", flags = re.IGNORECASE), \n",
    "            'GameTitle'] = \"California Games\"\n",
    "\n",
    "# Batman\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"Batman\", flags = re.IGNORECASE), \n",
    "            'GameTitle'] = \"Batman\"\n",
    "\n",
    "# Double Dragon\n",
    "cond1 = nes_df['Title'].str.contains(\"Double Dragon\", \n",
    "                                      flags = re.IGNORECASE)\n",
    "cond2 = nes_df['Title'].str.contains(\"^(?:(?!2).)+$|^(?:(?!Revenge).)+$\", flags = re.IGNORECASE)\n",
    "nes_df.loc[(cond1 & cond2), 'GameTitle'] = \"Double Dragon\"\n",
    "\n",
    "# Double Dragon II: The Revenge\n",
    "cond1 = nes_df['Title'].str.contains(\"Double Dragon\", \n",
    "                                      flags = re.IGNORECASE)\n",
    "cond2 = nes_df['Title'].str.contains(\"2|II|Revenge\", flags = re.IGNORECASE)\n",
    "nes_df.loc[(cond1 & cond2), 'GameTitle'] = \"Double Dragon II\"\n",
    "\n",
    "# The Simpsons: Bart vs the World\n",
    "cond1 = nes_df['Title'].str.contains(\"Bart\", \n",
    "                                      flags = re.IGNORECASE)\n",
    "cond2 = nes_df['Title'].str.contains(\"World\", flags = re.IGNORECASE)\n",
    "nes_df.loc[(cond1 & cond2), 'GameTitle'] = \"Bart vs the World\"\n",
    "\n",
    "# The Simpsons: Bartman Meets Radioactive Man\n",
    "cond1 = nes_df['Title'].str.contains(\"Bart|Simpson\", \n",
    "                                      flags = re.IGNORECASE)\n",
    "cond2 = nes_df['Title'].str.contains(\"Radioactive Man\", flags = re.IGNORECASE)\n",
    "nes_df.loc[(cond1 & cond2), 'GameTitle'] = \"Bartman Meets Radioactive Man\"\n",
    "\n",
    "# The Simpsons: Krusty's Fun House\n",
    "cond1 = nes_df['Title'].str.contains(\"Krusty\", \n",
    "                                      flags = re.IGNORECASE)\n",
    "cond2 = nes_df['Title'].str.contains(\"Fun House\", flags = re.IGNORECASE)\n",
    "nes_df.loc[(cond1 & cond2), 'GameTitle'] = \"Krustys Fun House\"\n",
    "\n",
    "# The Simpsons: Bart vs The Space Mutants\n",
    "cond1 = nes_df['Title'].str.contains(\"Bart|Simpson\", \n",
    "                                      flags = re.IGNORECASE)\n",
    "cond2 = nes_df['Title'].str.contains(\"Space Mutant|SpaceMutant\", flags = re.IGNORECASE)\n",
    "nes_df.loc[(cond1 & cond2), 'GameTitle'] = \"Bart vs The Space Mutants\"\n",
    "\n",
    "# Mega Man\n",
    "cond1 = nes_df['Title'].str.contains(\"Mega Man|MegaMan\", \n",
    "                                      flags = re.IGNORECASE)\n",
    "cond2 = nes_df['Title'].str.contains(\"^(?:(?!3).)+$|^(?:(?!3).)+$|^(?:(?!4).)+$\", flags = re.IGNORECASE)\n",
    "nes_df.loc[(cond1 & cond2), 'GameTitle'] = \"Mega Man\"\n",
    "\n",
    "# Mega Man 2\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"Mega Man 2|MegaMan 2\", flags = re.IGNORECASE), \n",
    "            'GameTitle'] = \"Mega Man 2\"\n",
    "\n",
    "# Mega Man 3\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"Mega Man 3|MegaMan 3\", flags = re.IGNORECASE), \n",
    "            'GameTitle'] = \"Mega Man 3\"\n",
    "\n",
    "# Mega Man 4\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"Mega Man 4|MegaMan 4\", flags = re.IGNORECASE), \n",
    "            'GameTitle'] = \"Mega Man 4\"\n",
    "\n",
    "# Mike Tyson's Punch Out\n",
    "nes_df.loc[nes_df['Title'].str.contains(\"Punch Out|Punch-Out|Punchout\", flags = re.IGNORECASE), \n",
    "            'GameTitle'] = \"Mike Tysons Punch Out\"\n",
    "\n",
    "# Donkey Kong\n",
    "cond1 = nes_df['Title'].str.contains(\"Donkey Kong\", \n",
    "                                      flags = re.IGNORECASE)\n",
    "cond2 = nes_df['Title'].str.contains(\"^(?:(?!Jr).)+$|^(?:(?!3).)+$\", flags = re.IGNORECASE)\n",
    "nes_df.loc[(cond1 & cond2), 'GameTitle'] = \"Donkey Kong\"\n",
    "\n",
    "# Donkey Kong Jr.\n",
    "cond1 = nes_df['Title'].str.contains(\"Donkey Kong\", \n",
    "                                      flags = re.IGNORECASE)\n",
    "cond2 = nes_df['Title'].str.contains(\"Jr\", flags = re.IGNORECASE)\n",
    "cond3 = nes_df['Title'].str.contains(\"^(?:(?!Math).)+$|^(?:(?!3).)+$\", flags = re.IGNORECASE)\n",
    "nes_df.loc[(cond1 & cond2 & cond3), 'GameTitle'] = \"Donkey Kong Jr.\"\n",
    "\n",
    "# Donkey Kong Jr. Math\n",
    "cond1 = nes_df['Title'].str.contains(\"Donkey Kong\", \n",
    "                                      flags = re.IGNORECASE)\n",
    "cond2 = nes_df['Title'].str.contains(\"Math\", flags = re.IGNORECASE)\n",
    "nes_df.loc[(cond1 & cond2), 'GameTitle'] = \"Donkey Kong Jr. Math\"\n",
    "\n",
    "# Donkey Kong 3\n",
    "cond1 = nes_df['Title'].str.contains(\"Donkey Kong\", \n",
    "                                      flags = re.IGNORECASE)\n",
    "cond2 = nes_df['Title'].str.contains(\"3\", flags = re.IGNORECASE)\n",
    "nes_df.loc[(cond1 & cond2), 'GameTitle'] = \"Donkey Kong 3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hasTitle = nes_df['GameTitle'] != \"\"\n",
    "nes_df = nes_df.loc[(hasTitle),]\n",
    "nes_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Translate the item condition\n",
    "nes_df['ConditionName'] = \"\"\n",
    "nes_df.loc[nes_df['ItemCondition'] == '6000', 'ConditionName'] = \"Acceptable\"\n",
    "nes_df.loc[nes_df['ItemCondition'] == '5000', 'ConditionName'] = \"Good\"\n",
    "nes_df.loc[nes_df['ItemCondition'] == '4000', 'ConditionName'] = \"Very Good\"\n",
    "nes_df.loc[nes_df['ItemCondition'] == '1000', 'ConditionName'] = \"New\"\n",
    "nes_df.loc[nes_df['ItemCondition'] == '3000', 'ConditionName'] = \"Used\"\n",
    "nes_df.loc[nes_df['ItemCondition'] == '2750', 'ConditionName'] = \"Like New\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nes_df['GameTitle'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Translate the currencies to AUD\n",
    "# Ending cost\n",
    "nes_df['EndingPrice'] = pd.to_numeric(nes_df['EndingPrice'])\n",
    "nes_df['EndingPriceAUD'] = nes_df['EndingPrice']\n",
    "nes_df.loc[nes_df['Currency'].str.contains(\"GBP\"), \n",
    "            'EndingPriceAUD'] = nes_df.loc[nes_df['Currency'].str.contains(\"GBP\"), 'EndingPriceAUD'] * 1.86\n",
    "nes_df.loc[nes_df['Currency'].str.contains(\"EUR\"), \n",
    "            'EndingPriceAUD'] = nes_df.loc[nes_df['Currency'].str.contains(\"EUR\"), 'EndingPriceAUD'] * 1.49\n",
    "\n",
    "# Shipping cost\n",
    "nes_df['ShippingCost'] = pd.to_numeric(nes_df['ShippingCost'])\n",
    "nes_df['ShippingCostAUD'] = nes_df['ShippingCost']\n",
    "nes_df.loc[nes_df['Currency'].str.contains(\"GBP\"), \n",
    "            'ShippingCostAUD'] = nes_df.loc[nes_df['Currency'].str.contains(\"GBP\"), 'ShippingCostAUD'] * 1.86\n",
    "nes_df.loc[nes_df['Currency'].str.contains(\"EUR\"), \n",
    "            'ShippingCostAUD'] = nes_df.loc[nes_df['Currency'].str.contains(\"EUR\"), 'ShippingCostAUD'] * 1.49\n",
    "\n",
    "# Total AUD cost\n",
    "nes_df['TotalAUDCost'] = nes_df['EndingPriceAUD'] + nes_df['ShippingCostAUD']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nes_df['ListingSold'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.round(nes_df[['EndingPriceAUD', 'GameTitle', 'ListingSold']].groupby(\n",
    "        ['GameTitle', 'ListingSold']).agg(['count', 'median']), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# http://www.neshq.com/lists/updatedrare60.txt\n",
    "nes_rarity = pd.read_csv(\"NES rarity.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nes_rarity = nes_rarity[['Title', 'Rarity']]\n",
    "nes_rarity[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nes_df = pd.merge(nes_df, nes_rarity, how = \"left\", left_on = \"GameTitle\", right_on = \"Title\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nes_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nes_df['Rarity'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Translate the game rarity\n",
    "nes_df['RarityDesc'] = \"\"\n",
    "nes_df.loc[nes_df['Rarity'] == 'D', 'RarityDesc'] = \"Common\"\n",
    "nes_df.loc[nes_df['Rarity'] == 'E', 'RarityDesc'] = \"Very Common\"\n",
    "nes_df.loc[nes_df['Rarity'] == 'F', 'RarityDesc'] = \"Unbelievably Common\"\n",
    "nes_df.loc[nes_df['Rarity'] == 'B-', 'RarityDesc'] = \"Borderline Rare\"\n",
    "nes_df.loc[nes_df['Rarity'] == 'C', 'RarityDesc'] = \"Uncommon\"\n",
    "nes_df.loc[nes_df['Rarity'] == 'C-', 'RarityDesc'] = \"Borderline Common\"\n",
    "nes_df.loc[nes_df['Rarity'] == 'B', 'RarityDesc'] = \"Rare\"\n",
    "nes_df.loc[nes_df['Rarity'] == 'C+', 'RarityDesc'] = \"Not Quite Rare\"\n",
    "nes_df.loc[nes_df['Rarity'] == 'A-', 'RarityDesc'] = \"These Will Require A Lot Of Looking\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nes_df['EndingPriceAUD'].hist(bins = 10)\n",
    "nes_df.to_csv(\"NES eBay data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(nes_df['EndingPriceAUD'], bins=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def expired_listings(site, searchterm):\n",
    "    '''Extracts the total historical listings from eBay for specific keywords and a specific global ID (eBay site), and then passes the results into a pandas DataFrame.'''\n",
    "    # Find out the number of pages of listings with the default number of listings per page.\n",
    "    url = 'http://svcs.ebay.com/services/search/FindingService/v1?OPERATION-NAME=findCompletedItems&SERVICE-VERSION=1.12.0&SECURITY-APPNAME=JodieBur-MarioBro-PRD-538ccaf50-bb20cf56&GLOBAL-ID=%s&RESPONSE-DATA-FORMAT=JSON&REST-PAYLOAD&keywords=%s&paginationInput.entriesPerPage=1' % (site, searchterm)\n",
    "    req = urllib2.Request(url)\n",
    "    text_data = urllib2.urlopen(req).read()\n",
    "    test = json.loads(text_data)\n",
    "    max = 1 + int(math.ceil(float(test.values()[0][0]['paginationOutput'][0]['totalEntries'][0]) / 100))\n",
    "\n",
    "    # Extract all listings and add the JSON to a single list.\n",
    "    data_all = []\n",
    "    for i in range(1, max):\n",
    "        url = 'http://svcs.ebay.com/services/search/FindingService/v1?OPERATION-NAME=findCompletedItems&SERVICE-VERSION=1.12.0&SECURITY-APPNAME=JodieBur-MarioBro-PRD-538ccaf50-bb20cf56&GLOBAL-ID=%s&RESPONSE-DATA-FORMAT=JSON&REST-PAYLOAD&keywords=%s&paginationInput.pageNumber=%d' % (site, searchterm, i)\n",
    "        req = urllib2.Request(url)\n",
    "        text_data = urllib2.urlopen(req).read()\n",
    "        data = json.loads(text_data)\n",
    "        data_all += data.values()[0][0]['searchResult'][0]['item']\n",
    "    \n",
    "    # Prepare the columns in the dataframe.\n",
    "    title = []\n",
    "    location = []\n",
    "    eBay_site = []\n",
    "    start_time = []\n",
    "    end_time = []\n",
    "    category = []\n",
    "    listing_type = []\n",
    "    item_condition = []\n",
    "    listing_sold = []\n",
    "    shipping_locations = []\n",
    "    shipping_cost = []\n",
    "    ending_price = []\n",
    "    currency = []\n",
    "    \n",
    "    # Pass the information from each listing into the column lists.\n",
    "    for i in range(0, len(data_all)):\n",
    "        title.append(data_all[i]['title'][0])\n",
    "        location.append(data_all[i]['location'][0])\n",
    "        eBay_site.append(data_all[i]['globalId'][0])\n",
    "        start_time.append(data_all[i]['listingInfo'][0]['startTime'][0])\n",
    "        end_time.append(data_all[i]['listingInfo'][0]['endTime'][0])\n",
    "        category.append(data_all[i]['primaryCategory'][0]['categoryName'][0])\n",
    "        listing_type.append(data_all[i]['listingInfo'][0]['listingType'][0])\n",
    "        if 'condition' in data_all[i]:\n",
    "            item_condition.append(data_all[i]['condition'][0]['conditionId'][0])\n",
    "        else:\n",
    "            item_condition.append(0)\n",
    "        listing_sold.append(data_all[i]['sellingStatus'][0]['sellingState'][0])\n",
    "        shipping_locations.append(data_all[i]['shippingInfo'][0]['shipToLocations'][0])\n",
    "        if 'shippingServiceCost' in data_all[i]['shippingInfo'][0]:\n",
    "            shipping_cost.append(data_all[i]['shippingInfo'][0]['shippingServiceCost'][0]['__value__'])\n",
    "        else:\n",
    "            shipping_cost.append(0)\n",
    "        ending_price.append(data_all[i]['sellingStatus'][0]['convertedCurrentPrice'][0]['__value__'])\n",
    "        currency.append(data_all[i]['sellingStatus'][0]['convertedCurrentPrice'][0]['@currencyId'])\n",
    "    \n",
    "    title = [t.encode('utf8') for t in title]\n",
    "    \n",
    "    # Pass all of the column lists into a DataFrame.\n",
    "    nes_df = DataFrame({'Title': title,\n",
    "                        'Location': location,\n",
    "                        'eBaySite': eBay_site,\n",
    "                        'StartDateTime': start_time,\n",
    "                        'EndDateTime': end_time,\n",
    "                        'Category': category,\n",
    "                        'ListingType': listing_type,\n",
    "                        'ItemCondition': item_condition,\n",
    "                        'ListingSold': listing_sold,\n",
    "                        'ShippingLocations': shipping_locations,\n",
    "                        'ShippingCost': shipping_cost,\n",
    "                        'EndingPrice': ending_price,\n",
    "                        'Currency': currency})\n",
    "    nes_df = nes_df[['Title', 'Location', 'eBaySite', 'StartDateTime', 'EndDateTime', 'Category',\n",
    "                     'ListingType', 'ItemCondition', 'ListingSold', 'ShippingLocations',\n",
    "                     'ShippingCost', 'EndingPrice', 'Currency']]\n",
    "    return nes_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ideas for features:\n",
    "    - Time of day\n",
    "    - Need to refactor condition and rarity to have suitable comparison group (least rare/worst condition if sufficiently big)\n",
    "    - Postage - worldwide vs other"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
